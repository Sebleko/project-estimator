{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human approval node\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, TypedDict\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class State(BaseModel):\n",
    "    llm_output: str\n",
    "    question: str\n",
    "    \n",
    "def human_approval(state):\n",
    "    print(\"Human approval node\")\n",
    "    answers = interrupt(\n",
    "        {\n",
    "            \"interrupt_type\": \"questions\",\n",
    "            \"questions\": [\"This is a question\", \"This is another question\"],\n",
    "            # Surface the output that should be\n",
    "            # reviewed and approved by the human.\n",
    "            \"llm_output\": state.llm_output\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Done\", answers)\n",
    "\n",
    "# Add the node to the graph in an appropriate location\n",
    "# and connect it to the relevant nodes.\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.set_entry_point(\"human_approval\")\n",
    "graph_builder.add_node(\"human_approval\", human_approval)\n",
    "graph_builder.add_edge(\"human_approval\", END)\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "checkpointer = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "initial_state = State(llm_output=\"This is a test\", question=\"Is this correct?\")\n",
    "result = graph.invoke(initial_state, config=thread_config)\n",
    "# After running the graph and hitting the interrupt, the graph will pause.\n",
    "# Resume it with either an approval or rejection.\n",
    "#graph.invoke(Command(resume=True), config=thread_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interrupt_type': 'questions',\n",
       " 'questions': ['This is a question', 'This is another question'],\n",
       " 'llm_output': 'This is a test'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "tasks = state.tasks[0].interrupts[0].value\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: This is a question\n",
      "Question: This is another question\n"
     ]
    }
   ],
   "source": [
    "answers = {}\n",
    "if tasks[\"interrupt_type\"] == \"questions\":\n",
    "    for question in tasks[\"questions\"]:\n",
    "        print(f\"Question: {question}\")\n",
    "        answer = input(\"Answer: \")\n",
    "        answers[question] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This is a question': 'a', 'This is another question': 'b'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human approval node\n",
      "Done {'This is a question': 'a', 'This is another question': 'b'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 'This is a test', 'question': 'Is this correct?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = await graph.ainvoke(Command(resume=answers), config=thread_config)\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'llm_output': 'This is a test', 'question': 'Is this correct?'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1eff5cf8-96d4-618e-8001-8350e00d2ca4'}}, metadata={'source': 'loop', 'writes': {'human_approval': None}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-02-28T12:28:38.444875+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1eff5cf8-7881-606a-8000-0e778d11eafe'}}, tasks=())"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "state\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
